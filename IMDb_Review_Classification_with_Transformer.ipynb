{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "5e068a4e",
        "fe05f19e",
        "41EUh0wCRwKw",
        "VIiL9d8MRyEI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "345b74c5",
        "papermill": {
          "duration": 0.008945,
          "end_time": "2023-06-17T03:45:51.629348",
          "exception": false,
          "start_time": "2023-06-17T03:45:51.620403",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# IMDb Review Classification using Transformers\n",
        "\n",
        "**Author:** Sarang Galada<br>\n",
        "**Email ID:** sarang.galada@gmail.com<br>\n",
        "**Date created:** 07/11/2023<br><br>\n",
        "**Description:** Classification of IMDb movie reviews as `positive` or `negative` using Transformers and `keras_nlp`\n",
        "\n",
        "*   *Problem*: Binary text classification\n",
        "*   *Dataset*: IMDb movie reviews\n",
        "*   *Model*: Transformer based\n",
        "*   *Key library used*: `keras_nlp`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scheme**\n",
        "\n",
        "\n",
        "1.   Load required libraries\n",
        "2.   Load raw data\n",
        "3.   Prepare text data\n",
        "4.   Vectorize text data into embeddings\n",
        "5.   Construct Transformer model\n",
        "6.   Train model\n",
        "7.   Evaluate model"
      ],
      "metadata": {
        "id": "N8WXoT1-PAvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the libraries\n",
        "\n",
        "Before we start with the implementation, let's import all the necessary packages."
      ],
      "metadata": {
        "id": "r-ciOSnhRJFh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-17T03:45:51.681173Z",
          "iopub.status.busy": "2023-06-17T03:45:51.680423Z",
          "iopub.status.idle": "2023-06-17T03:46:04.511692Z",
          "shell.execute_reply": "2023-06-17T03:46:04.510505Z"
        },
        "papermill": {
          "duration": 12.843603,
          "end_time": "2023-06-17T03:46:04.514686",
          "exception": false,
          "start_time": "2023-06-17T03:45:51.671083",
          "status": "completed"
        },
        "tags": [],
        "id": "c22b5d88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f94eac-0035-40c7-cb17-d828b4c0792e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.5/584.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install keras-nlp -q --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-17T03:46:04.535349Z",
          "iopub.status.busy": "2023-06-17T03:46:04.535018Z",
          "iopub.status.idle": "2023-06-17T03:46:13.321598Z",
          "shell.execute_reply": "2023-06-17T03:46:13.320631Z"
        },
        "id": "62249043",
        "papermill": {
          "duration": 8.799372,
          "end_time": "2023-06-17T03:46:13.324129",
          "exception": false,
          "start_time": "2023-06-17T03:46:04.524757",
          "status": "completed"
        },
        "tags": [],
        "outputId": "61a910f5-aa97-44e8-8aa8-2676cccc54ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "# Importing required libraries\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_nlp\n",
        "\n",
        "keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d6b0e82",
        "papermill": {
          "duration": 0.008418,
          "end_time": "2023-06-17T03:46:13.341288",
          "exception": false,
          "start_time": "2023-06-17T03:46:13.332870",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Let's also define our hyperparameters upfront."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-17T03:46:13.360726Z",
          "iopub.status.busy": "2023-06-17T03:46:13.359629Z",
          "iopub.status.idle": "2023-06-17T03:46:13.364925Z",
          "shell.execute_reply": "2023-06-17T03:46:13.363910Z"
        },
        "id": "cb92c7c5",
        "papermill": {
          "duration": 0.017086,
          "end_time": "2023-06-17T03:46:13.367123",
          "exception": false,
          "start_time": "2023-06-17T03:46:13.350037",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 3\n",
        "MAX_SEQUENCE_LENGTH = 512\n",
        "VOCAB_SIZE = 15000\n",
        "\n",
        "EMBED_DIM = 128\n",
        "INTERMEDIATE_DIM = 512\n",
        "NUM_HEADS = 2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE = 32\n",
        "# EPOCHS = 5\n",
        "# MAX_SEQUENCE_LENGTH = 150   # Only consider the first 150 words of each movie review\n",
        "# VOCAB_SIZE = 20000  # Only consider the top 20k frequently ocurring words of the vocabulary\n",
        "\n",
        "# EMBED_DIM = 256\n",
        "# INTERMEDIATE_DIM = 512\n",
        "# NUM_HEADS = 8"
      ],
      "metadata": {
        "id": "mPWu7feMHBAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b66bbc9",
        "papermill": {
          "duration": 0.008622,
          "end_time": "2023-06-17T03:46:13.384375",
          "exception": false,
          "start_time": "2023-06-17T03:46:13.375753",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Loading the raw data\n",
        "\n",
        "Download and extract the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=VOCAB_SIZE)\n",
        "# print(x_train.size)  # No. of training text sequences\n",
        "# print(x_test.size)   # No. of testing text sequences"
      ],
      "metadata": {
        "id": "lUdEzRwgFUog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "# !tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElstztAgNVja",
        "outputId": "7a488e29-148b-45b5-81f4-6021c8b95181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  3241k      0  0:00:25  0:00:25 --:--:-- 1954k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-17T03:46:13.402800Z",
          "iopub.status.busy": "2023-06-17T03:46:13.402501Z",
          "iopub.status.idle": "2023-06-17T03:46:25.257627Z",
          "shell.execute_reply": "2023-06-17T03:46:25.256375Z"
        },
        "id": "f0ceb741",
        "papermill": {
          "duration": 11.867188,
          "end_time": "2023-06-17T03:46:25.260135",
          "exception": false,
          "start_time": "2023-06-17T03:46:13.392947",
          "status": "completed"
        },
        "tags": [],
        "outputId": "0e3eda8e-032d-4a3a-b41b-fcb12d1a5edd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-12 08:27:55--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  10.9MB/s    in 10s     \n",
            "\n",
            "2023-11-12 08:28:06 (7.65 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xzf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us inspect the raw data files"
      ],
      "metadata": {
        "id": "bhcgGbBVRG9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyRcthDCcjMd",
        "outputId": "2f7a57fd-4040-4de8-dadf-ddb0c83e62b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdbEr.txt  imdb.vocab\tREADME\ttest  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f6f69e7",
        "papermill": {
          "duration": 0.010256,
          "end_time": "2023-06-17T03:46:25.333769",
          "exception": false,
          "start_time": "2023-06-17T03:46:25.323513",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The directory contains two sub-directories: `train` and `test`. Each subdirectory\n",
        "in turn contains two folders: `pos` and `neg` for positive and negative reviews,\n",
        "respectively."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_szBZVhLckh6",
        "outputId": "a0e77273-2864-4cc6-a5f3-5befa938b01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  neg  pos  unsup  unsupBow.feat  urls_neg.txt  urls_pos.txt  urls_unsup.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb/test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeFvw892cns5",
        "outputId": "db9fa8fd-5bc4-49d2-cd8e-565859c155ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  neg  pos  urls_neg.txt  urls_pos.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a supervised learning project, hence let's delete the `./aclImdb/train/unsup`\n",
        "folder since it has unlabelled samples."
      ],
      "metadata": {
        "id": "-bXbG07IRc44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "idKFBkyYc8cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "042e3152",
        "papermill": {
          "duration": 0.010464,
          "end_time": "2023-06-17T03:46:27.246001",
          "exception": false,
          "start_time": "2023-06-17T03:46:27.235537",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Use the `keras.utils.text_dataset_from_directory` utility to generate\n",
        "our labelled `tf.data.Dataset` dataset from text files."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the data\n",
        "\n",
        "The data in its current form is raw and needs to be preprocessed"
      ],
      "metadata": {
        "id": "9WBbXUpscvsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        ")\n",
        "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        ")\n",
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\",\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(f\"\\nNumber of batches (batch_size={BATCH_SIZE}) in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
        "print(f\"Number of batches (batch_size={BATCH_SIZE}) in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
        "print(f\"Number of batches (batch_size={BATCH_SIZE}) in raw_test_ds: {raw_test_ds.cardinality()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUp_4AYGNt3g",
        "outputId": "a3113f8b-85bf-4288-dab3-8bffbf5b557a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "\n",
            "Number of batches (batch_size=64) in raw_train_ds: 313\n",
            "Number of batches (batch_size=64) in raw_val_ds: 79\n",
            "Number of batches (batch_size=64) in raw_test_ds: 391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A peep into the IMDb reviews training set"
      ],
      "metadata": {
        "id": "7_QXes-xS2Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in raw_train_ds.take(1):\n",
        "    for i in range(5):\n",
        "        print((text_batch.numpy()[i]))\n",
        "        print(label_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-VPzyY2LCPv",
        "outputId": "7d44b240-3908-47ed-ac53-861df3068639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'An illegal immigrant resists the social support system causing dire consequences for many. Well filmed and acted even though the story is a bit forced, yet the slow pacing really sets off the conclusion. The feeling of being lost in the big city is effectively conveyed. The little person lost in the big society is something to which we can all relate, but I cannot endorse going out of your way to see this movie.'\n",
            "0\n",
            "b\"To get in touch with the beauty of this film pay close attention to the sound track, not only the music, but the way all sounds help to weave the imagery. How beautifully the opening scene leading to the expulsion of Gino establishes the theme of moral ambiguity! Note the way music introduces the characters as we are led inside Giovanna's marriage. Don't expect to find much here of the political life of Italy in 1943. That's not what this is about. On the other hand, if you are susceptible to the music of images and sounds, you will be led into a word that reaches beyond neo-realism. By the end of the film we there are moments Antonioni-like landscape that has more to do with the inner life of the characters than with real places. This is one of my favorite Visconti films.\"\n",
            "1\n",
            "b'\"Hollywood Hotel\" has relationships to many films like \"Ella Cinders\" and \"Merton of the Movies\" about someone winning a contest including a contract to make films in Hollywood, only to find the road to stardom either paved with pitfalls or non-existent. In fact, as I was watching it tonight, on Turner Classic Movies, I was considering whether or not the authors of the later musical classic \"Singing In The Rain\" may have taken some of their ideas from \"Hollywood Hotel\", most notably a temperamental leading lady star in a movie studio and a conclusion concerning one person singing a film score while another person got the credit by mouthing along on screen.<br /><br />\"Hollywood Hotel\" is a fascinating example of movie making in the 1930s. Among the supporting players is Louella Parsons, playing herself (and, despite some negative comments I\\'ve seen, she has a very ingratiating personality on screen and a natural command of her lines). She is not the only real person in the script. Make-up specialist Perc Westmore briefly appears as himself to try to make one character resemble another.<br /><br />This film also was one of the first in the career of young Mr. Ronald Reagan, playing a radio interviewer at a movie premiere. Reagan actually does quite nicely in his brief scenes - particularly when he realizes that nobody Dick Powell is about to take over the microphone when it should be used with more important people.<br /><br />Dick Powell has won a Hollywood contract in a contest, and is leaving his job as a saxophonist in Benny Goodman\\'s band. The beginning of this film, by the way, is quite impressive, as the band drives in a parade of trucks to give a proper goodbye to Powell. They end up singing \"Hooray For Hollywood\". The interesting thing about this wonderful number is that a lyric has been left out on purpose. Throughout the Johnny Mercer lyrics are references to such Hollywood as Max Factor the make-up king, Rin tin tin, and even a hint of Tarzan. But the original song lyric referred to looking like Tyrone Power. Obviously Jack Warner and his brothers were not going to advertise the leading man of 20th Century Fox, and the name Donald Duck was substituted. In any event the number showed the singers and instrumentalists of Goodman\\'s orchestra at their best. So did a later five minute section of the film, where the band is rehearsing.<br /><br />Powell leaves the band and his girl friend (Frances Langford) and goes to Hollywood, only to find he is a contract player (most likely for musicals involving saxophonists). He is met by Allen Joslyn, the publicist of the studio (the owner is Grant Mitchell). Joslyn is not a bad fellow, but he is busy and he tends to slough off people unless it is necessary to speak to them. He parks Powell at a room at the Hollywood Hotel, which is also where the studio\\'s temperamental star (Lola Lane) lives with her father (Hugh Herbert), her sister (Mabel Todd), and her sensible if cynical assistant (Glenda Farrell). Lane is like Jean Hagen in \"Singing In The Rain\", except her speaking voice is good. Her version of \"Dan Lockwood\" is one \"Alexander Dupre\" (Alan Mowbray, scene stealing with ease several times). The only difference is that Mowbray is not a nice guy like Gene Kelly was, and Lane (when not wrapped up in her ego) is fully aware of it. Having a fit on being by-passed for an out-of-the ordinary role she wanted, she refuses to attend the premiere of her latest film. Joslyn finds a double for her (Lola\\'s real life sister Rosemary Lane), and Rosemary is made up to play the star at the premiere and the follow-up party. But she attends with Powell (Joslyn wanting someone who doesn\\'t know the real Lola). This leads to Powell knocking down Mowbray when the latter makes a pest of himself. But otherwise the evening is a success, and when the two are together they start finding each other attractive.<br /><br />The complications deal with Lola coming back and slapping Powell in the face, after Mowbray complains he was attacked by Powell (\"and his gang of hoodlums\"). Powell\\'s contract is bought out. Working with photographer turned agent Ted Healey (actually not too bad in this film - he even tries to do a Jolson imitation at one point), the two try to find work, ending up as employees at a hamburger stand run by bad tempered Edgar Kennedy (the number of broken dishes and singing customers in the restaurant give Edgar plenty of time to do his slow burns with gusto). Eventually Powell gets a \"break\" by being hired to be Dupre\\'s singing voice in a rip-off of \"Gone With The Wind\". This leads to the final section of the film, when Rosemary Lane, Herbert, and Healey help give Powell his chance to show it\\'s his voice, not Mowbrays.<br /><br />It\\'s quite a cute and appealing film even now. The worst aspects are due to it\\'s time. Several jokes concerning African-Americans are no longer tolerable (while trying to photograph Powell as he arrives in Hollywood, Healey accidentally photographs a porter, and mentions to Joslyn to watch out, Powell photographs too darkly - get the point?). Also a bit with Curt Bois as a fashion designer for Lola Lane, who is (shall we say) too high strung is not very tolerable either. Herbert\\'s \"hoo-hoo\"ing is a bit much (too much of the time) but it was really popular in 1937. And an incident where Healey nearly gets into a brawl at the premiere (this was one of his last films) reminds people of the tragic, still mysterious end of the comedian in December 1937. But most of the film is quite good, and won\\'t disappoint the viewer in 2008.'\n",
            "1\n",
            "b'What starts out as a very predictable and somewhat drab affair is in the end quite hilarious and entertaining. \"Right to Die\" is not very suspenseful but it more than makes up for that with some outlandish set pieces and over the top gore.<br /><br />Spoilers here: <br /><br />Top credits also go to the dead-on performance from Martin Donovan as one of the most despicable characters ever to grace the screen. Playing the character in a great \"aloof\" fashion, you nearly feel bad for the guy in the end when his grand plan ultimately fails. Corbin Bernsen also chews up the scenery playing a not-so-good-guy who gets his just desserts.<br /><br />End of Spoiler.<br /><br />As a revenge-from-the-dead flick, \"Right to Die\" benefits heavily from it\\'s performers and is more than an OK way to spend less than an hour.'\n",
            "1\n",
            "b\"I loved this movie since I was 7 and I saw it on the opening day. It was so touching and beautiful. I strongly recommend seeing for all. It's a movie to watch with your family by far.<br /><br />My MPAA rating: PG-13 for thematic elements, prolonged scenes of disastor, nudity/sexuality and some language.\"\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed3a15cf",
        "papermill": {
          "duration": 0.010889,
          "end_time": "2023-06-17T03:46:36.390508",
          "exception": false,
          "start_time": "2023-06-17T03:46:36.379619",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "We will now preprocess the text:<br>\n",
        "\n",
        "1.   Convert text to lowercase\n",
        "2.   Remove HTML tags\n",
        "3.   Remove punctuations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation),\n",
        "                                  '')"
      ],
      "metadata": {
        "id": "TGaEMTfULU5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = raw_train_ds.map(lambda x, y: (custom_standardization(x), y))\n",
        "val_ds = raw_val_ds.map(lambda x, y: (custom_standardization(x), y))\n",
        "test_ds = raw_test_ds.map(lambda x, y: (custom_standardization(x), y))\n"
      ],
      "metadata": {
        "id": "BfJ-cnshOhYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc9defb2",
        "papermill": {
          "duration": 0.011008,
          "end_time": "2023-06-17T03:46:36.519883",
          "exception": false,
          "start_time": "2023-06-17T03:46:36.508875",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Let's print a few samples after preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(5):\n",
        "        print((text_batch.numpy()[i]))\n",
        "        print(label_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GW5ALBbPUhJ",
        "outputId": "c3a931cd-e0d5-439b-8071-6df03ed585b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'nobody said movies had to be realistic did they i really liked this movie because i remember when i first saw it in junior high for all the kids who remember the pmrc and albums before there were warning stickers its a cool story for all those kids who were part of the mid to late 80s headbanger crowd'\n",
            "1\n",
            "b'a different look at horror the styling differences between american and russian films is interesting however from my american perspective this movie just wasnt that good the protagonist marie played by anastasia hille wasnt a pleasant character and i had a hard time identifying with her she was disagreeable most of the time and confused for much of what little time was left also too much time was spent in bringing her to the main location of the film then a long time passed before any real suspense built up once that happened it seemed volume was used as the main effect which was more annoying than anything else the concept was more original than most directtovideo movies and they didnt use sex to make up for a thin plot all in all id recommend it for renting but not for theater goers'\n",
            "0\n",
            "b'the movie atlantis the lost empire is a shining gem in the rubble of films produced by the disney studios recently parents who have had to sit through the jungle book 2 or even a pokemon movie will surely appreciate this one  the film is one of few to attempt at an original story previous feature films were merely re tellings of existing stories films such as toy story finding nemo and monsters inc all do the same but it must be noted that all were made by pixar and only distributed by disney recent films from the disney studios are mostly released direct to video and are sequels to an existing successful film the quality of those films is given way to the profitability a new era started with atlantis following it were mulan lilo  stitch and most recently open range the writers have created all original story lines instead of the fairy tales of the past  a good portion of the movie is devoted to the quest to find atlantis a task that has captured the imagination of many for hundreds of years including that of young milo thatch voiced by michael j fox milo is employed by a museum in washington dc his grandfather was a renowned archaeologist who had devoted his life to discovering atlantis this was seen as a waste by his peers and they wish milo to not follow in his footsteps after failing to convince the museum board of directors to sponsor his expedition milo comes home to find a woman in his darkened apartment she takes him to her employer a mr whitmore whitmore was a close friend of milos grandfather and wishes to send milo with a team to locate atlantis mr whitmore is very wealth and has paid for the best of everything the crew that is to accompany him is the same as his grandfathers the journey is filled with many great obstacles to overcome and is great fun to watch the viewer finds themselves caught up in if they will reach atlantis the plot takes an unexpected turn after the discovery atlantis not just the discovery of people it is enough to keep the interest of the older audience  the animators have done a wonderful job in then depth of the animation the movie is very successful in blending traditional animation with computer generated images a feat not easily achieved most audiences are quick to notice the difference in the two the characters are believably human there are some nice chase type scenes with lots of action going on a few lulls are filled with jokes that the children just may not get  the creativity of the writers really shines through the culture of atlantis is richly developed including an entire language the film uses references to atlantis from historical sources such as plato the disappearance of atlantis from the world is explained believable if by a younger audience that magic really does exist the powers of the people of atlantis are not exactly presented as magic but can best be described in this way  although set in 1914 the level of technology used is unrealistic the voyage is in a submarine very reminiscent of captain nemos nautilus complete with sub pods that fire torpedoes the giant diggers are driven by steam boilers so they did try for some era technology the female characters are empowered in a way that women of the age would not have been even holding roles in leadership this is not a bad thing it gives a good role model for my daughter to look to rather than an all male cast  one reason this film is a favorite of mine over other disney films is that there is not one single song ever a tradition that began with the first feature film snow white and carried on through to the lion king almost every disney film is full of upbeat songs this is great and all what would the seven dwarfs be without hi ho after the millionth time through itd almost be better without but this one spares the parent not once does every single person on the screen suddenly know the words to a song that no one has ever heard before and break out in song i for one am grateful  the storyline and depth of animation is sure to keep the attention of both parent and child alike it is a film i am willing to watch again and again with my children'\n",
            "1\n",
            "b'this movie is a touching story about an adventure taken by 15yearold darius weems darius has duchenne muscular dystrophy a still uncurable disease that took the life of his brother at age nineteen and is the number one killer of babies in the united states him and a few close friends travel across the country to los angeles with the goal of getting his wheelchair customized on mtvs pimp my ride one of his favorite shows the journey begins in georgia where darius grew up and has never left the gang head west for a trip that all its participants will never forget darius gets to ride in a boat for the first time ride in a hot air balloon swim in the ocean and visit sights hes always wanted to see like the grand canyon and new orleans the filmmakers here clearly have an emotional connection to the material they make no money from sales of the 20 dvds 17 goes toward researching the disease and 3 goes toward making more copies the film has won over 25 awards at festivals and i agree with the quote given to the film by variety certain to stir hearts'\n",
            "1\n",
            "b'in this installment of the series edmund blackadder is stuck in the regency period in britain during the later portion of george iiis rule this time blackadders prospects are much pooreras instead of royalty hes a servant to the very very thick george iv the price regent unlike the historical accounts of george iv this one is about as bright as a tomato and as a result blackadders able to take advantage of him and scheme to his hearts content the only major difference in style between this one and earlier ones is that the series ends on a very very very different noteyou just have to see it to believe it other than that all the usual story elements are there and the show is hilarious the only reservation i have as always is that this show is not appropriate for the kids due to its crude language and adult situations'\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-17T03:46:36.417506Z",
          "iopub.status.busy": "2023-06-17T03:46:36.417164Z",
          "iopub.status.idle": "2023-06-17T03:46:36.495459Z",
          "shell.execute_reply": "2023-06-17T03:46:36.494450Z"
        },
        "id": "702bd42d",
        "papermill": {
          "duration": 0.09587,
          "end_time": "2023-06-17T03:46:36.497562",
          "exception": false,
          "start_time": "2023-06-17T03:46:36.401692",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# train_ds = train_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "# val_ds = val_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "# test_ds = test_ds.map(lambda x, y: (tf.strings.lower(x), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-17T03:46:36.543409Z",
          "iopub.status.busy": "2023-06-17T03:46:36.543122Z",
          "iopub.status.idle": "2023-06-17T03:46:36.659730Z",
          "shell.execute_reply": "2023-06-17T03:46:36.658771Z"
        },
        "id": "d323fdf6",
        "papermill": {
          "duration": 0.131092,
          "end_time": "2023-06-17T03:46:36.662057",
          "exception": false,
          "start_time": "2023-06-17T03:46:36.530965",
          "status": "completed"
        },
        "tags": [],
        "outputId": "1e4136f8-974d-4c36-f2f1-5ee16ec48811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'an illegal immigrant resists the social support system causing dire consequences for many. well filmed and acted even though the story is a bit forced, yet the slow pacing really sets off the conclusion. the feeling of being lost in the big city is effectively conveyed. the little person lost in the big society is something to which we can all relate, but i cannot endorse going out of your way to see this movie.'\n",
            "0\n",
            "b\"to get in touch with the beauty of this film pay close attention to the sound track, not only the music, but the way all sounds help to weave the imagery. how beautifully the opening scene leading to the expulsion of gino establishes the theme of moral ambiguity! note the way music introduces the characters as we are led inside giovanna's marriage. don't expect to find much here of the political life of italy in 1943. that's not what this is about. on the other hand, if you are susceptible to the music of images and sounds, you will be led into a word that reaches beyond neo-realism. by the end of the film we there are moments antonioni-like landscape that has more to do with the inner life of the characters than with real places. this is one of my favorite visconti films.\"\n",
            "1\n",
            "b'\"hollywood hotel\" has relationships to many films like \"ella cinders\" and \"merton of the movies\" about someone winning a contest including a contract to make films in hollywood, only to find the road to stardom either paved with pitfalls or non-existent. in fact, as i was watching it tonight, on turner classic movies, i was considering whether or not the authors of the later musical classic \"singing in the rain\" may have taken some of their ideas from \"hollywood hotel\", most notably a temperamental leading lady star in a movie studio and a conclusion concerning one person singing a film score while another person got the credit by mouthing along on screen.<br /><br />\"hollywood hotel\" is a fascinating example of movie making in the 1930s. among the supporting players is louella parsons, playing herself (and, despite some negative comments i\\'ve seen, she has a very ingratiating personality on screen and a natural command of her lines). she is not the only real person in the script. make-up specialist perc westmore briefly appears as himself to try to make one character resemble another.<br /><br />this film also was one of the first in the career of young mr. ronald reagan, playing a radio interviewer at a movie premiere. reagan actually does quite nicely in his brief scenes - particularly when he realizes that nobody dick powell is about to take over the microphone when it should be used with more important people.<br /><br />dick powell has won a hollywood contract in a contest, and is leaving his job as a saxophonist in benny goodman\\'s band. the beginning of this film, by the way, is quite impressive, as the band drives in a parade of trucks to give a proper goodbye to powell. they end up singing \"hooray for hollywood\". the interesting thing about this wonderful number is that a lyric has been left out on purpose. throughout the johnny mercer lyrics are references to such hollywood as max factor the make-up king, rin tin tin, and even a hint of tarzan. but the original song lyric referred to looking like tyrone power. obviously jack warner and his brothers were not going to advertise the leading man of 20th century fox, and the name donald duck was substituted. in any event the number showed the singers and instrumentalists of goodman\\'s orchestra at their best. so did a later five minute section of the film, where the band is rehearsing.<br /><br />powell leaves the band and his girl friend (frances langford) and goes to hollywood, only to find he is a contract player (most likely for musicals involving saxophonists). he is met by allen joslyn, the publicist of the studio (the owner is grant mitchell). joslyn is not a bad fellow, but he is busy and he tends to slough off people unless it is necessary to speak to them. he parks powell at a room at the hollywood hotel, which is also where the studio\\'s temperamental star (lola lane) lives with her father (hugh herbert), her sister (mabel todd), and her sensible if cynical assistant (glenda farrell). lane is like jean hagen in \"singing in the rain\", except her speaking voice is good. her version of \"dan lockwood\" is one \"alexander dupre\" (alan mowbray, scene stealing with ease several times). the only difference is that mowbray is not a nice guy like gene kelly was, and lane (when not wrapped up in her ego) is fully aware of it. having a fit on being by-passed for an out-of-the ordinary role she wanted, she refuses to attend the premiere of her latest film. joslyn finds a double for her (lola\\'s real life sister rosemary lane), and rosemary is made up to play the star at the premiere and the follow-up party. but she attends with powell (joslyn wanting someone who doesn\\'t know the real lola). this leads to powell knocking down mowbray when the latter makes a pest of himself. but otherwise the evening is a success, and when the two are together they start finding each other attractive.<br /><br />the complications deal with lola coming back and slapping powell in the face, after mowbray complains he was attacked by powell (\"and his gang of hoodlums\"). powell\\'s contract is bought out. working with photographer turned agent ted healey (actually not too bad in this film - he even tries to do a jolson imitation at one point), the two try to find work, ending up as employees at a hamburger stand run by bad tempered edgar kennedy (the number of broken dishes and singing customers in the restaurant give edgar plenty of time to do his slow burns with gusto). eventually powell gets a \"break\" by being hired to be dupre\\'s singing voice in a rip-off of \"gone with the wind\". this leads to the final section of the film, when rosemary lane, herbert, and healey help give powell his chance to show it\\'s his voice, not mowbrays.<br /><br />it\\'s quite a cute and appealing film even now. the worst aspects are due to it\\'s time. several jokes concerning african-americans are no longer tolerable (while trying to photograph powell as he arrives in hollywood, healey accidentally photographs a porter, and mentions to joslyn to watch out, powell photographs too darkly - get the point?). also a bit with curt bois as a fashion designer for lola lane, who is (shall we say) too high strung is not very tolerable either. herbert\\'s \"hoo-hoo\"ing is a bit much (too much of the time) but it was really popular in 1937. and an incident where healey nearly gets into a brawl at the premiere (this was one of his last films) reminds people of the tragic, still mysterious end of the comedian in december 1937. but most of the film is quite good, and won\\'t disappoint the viewer in 2008.'\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# for text_batch, label_batch in train_ds.take(1):\n",
        "#     for i in range(3):\n",
        "#         print(text_batch.numpy()[i])\n",
        "#         print(label_batch.numpy()[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9aa0e03",
        "papermill": {
          "duration": 0.011157,
          "end_time": "2023-06-17T03:46:36.684896",
          "exception": false,
          "start_time": "2023-06-17T03:46:36.673739",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Tokenizing the data\n",
        "\n",
        "In order to tokenize our dataset, we must first train the `keras_nlp` tokenizer on the text corpus in order to get a vocabulary of subwords.\n",
        "\n",
        "The trained tokenizer can then be applied to the subwords in the vocabulary to encode them into tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
        "\n",
        "def train_word_piece(ds, vocab_size, reserved_tokens):\n",
        "    word_piece_ds = ds.unbatch().map(lambda x, y: x)\n",
        "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
        "        word_piece_ds.batch(1000).prefetch(2),\n",
        "        vocabulary_size=vocab_size,\n",
        "        reserved_tokens=reserved_tokens,\n",
        "    )\n",
        "    return vocab\n",
        "\n",
        "train_sentences = [element[0] for element in train_ds]\n",
        "vocab = train_word_piece(train_ds, VOCAB_SIZE, reserved_tokens)"
      ],
      "metadata": {
        "id": "Q0LL_JqQUBAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab440beb",
        "papermill": {
          "duration": 0.011406,
          "end_time": "2023-06-17T03:51:10.881563",
          "exception": false,
          "start_time": "2023-06-17T03:51:10.870157",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Let's see some tokens!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-17T03:51:10.905687Z",
          "iopub.status.busy": "2023-06-17T03:51:10.905364Z",
          "iopub.status.idle": "2023-06-17T03:51:10.910803Z",
          "shell.execute_reply": "2023-06-17T03:51:10.909668Z"
        },
        "id": "b2f97fc8",
        "papermill": {
          "duration": 0.019885,
          "end_time": "2023-06-17T03:51:10.912877",
          "exception": false,
          "start_time": "2023-06-17T03:51:10.892992",
          "status": "completed"
        },
        "tags": [],
        "outputId": "ab479af7-b037-406e-8fd8-68d255fa831a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens:  ['à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é']\n"
          ]
        }
      ],
      "source": [
        "print(\"Tokens: \", vocab[100:110])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6338e1d9",
        "papermill": {
          "duration": 0.01125,
          "end_time": "2023-06-17T03:51:10.935680",
          "exception": false,
          "start_time": "2023-06-17T03:51:10.924430",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Now, let's define the tokenizer. We will configure the tokenizer with the\n",
        "the vocabularies trained above. We will define a maximum sequence length so that\n",
        "all sequences are padded to the same length, if the length of the sequence is\n",
        "less than the specified sequence length. Otherwise, the sequence is truncated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-17T03:51:10.960285Z",
          "iopub.status.busy": "2023-06-17T03:51:10.959920Z",
          "iopub.status.idle": "2023-06-17T03:51:11.197181Z",
          "shell.execute_reply": "2023-06-17T03:51:11.196034Z"
        },
        "id": "150caf04",
        "papermill": {
          "duration": 0.252599,
          "end_time": "2023-06-17T03:51:11.199927",
          "exception": false,
          "start_time": "2023-06-17T03:51:10.947328",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab,\n",
        "    lowercase=False,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f4d92e6",
        "papermill": {
          "duration": 0.012863,
          "end_time": "2023-06-17T03:51:11.226518",
          "exception": false,
          "start_time": "2023-06-17T03:51:11.213655",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Let's try and tokenize a sample from our dataset! To verify whether the text has\n",
        "been tokenized correctly, we can also detokenize the list of tokens back to the\n",
        "original text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-17T03:51:11.254133Z",
          "iopub.status.busy": "2023-06-17T03:51:11.253766Z",
          "iopub.status.idle": "2023-06-17T03:51:11.438688Z",
          "shell.execute_reply": "2023-06-17T03:51:11.437626Z"
        },
        "id": "18c1bb5c",
        "papermill": {
          "duration": 0.201018,
          "end_time": "2023-06-17T03:51:11.440949",
          "exception": false,
          "start_time": "2023-06-17T03:51:11.239931",
          "status": "completed"
        },
        "tags": [],
        "outputId": "da56204d-fd09-4c87-be9a-50243434aae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  tf.Tensor(b'this picture seemed way to slanted, it\\'s almost as bad as the drum beating of the right wing kooks who say everything is rosy in iraq. it paints a picture so unredeemable that i can\\'t help but wonder about it\\'s legitimacy and bias. also it seemed to meander from being about the murderous carnage of our troops to the lack of health care in the states for ptsd. to me the subject matter seemed confused, it only cared about portraying the military in a bad light, as a) an organzation that uses mind control to turn ordinary peace loving civilians into baby killers and b) an organization that once having used and spent the bodies of it\\'s soldiers then discards them to the despotic bureacracy of the v.a. this is a legitimate argument, but felt off topic for me, almost like a movie in and of itself. i felt that \"the war tapes\" and \"blood of my brother\" were much more fair and let the viewer draw some conclusions of their own rather than be beaten over the head with the film makers viewpoint. f-', shape=(), dtype=string)\n",
            "Tokens:  tf.Tensor(\n",
            "[  145   576   608   228   140    58 13343    13   143     8    58   360\n",
            "   148   209   148   137  9759  3681   139   137   344  3276    50 12092\n",
            "   164   169   269   424   141    57  2093   292   144  5115    15   143\n",
            "  7890    40   576   170  2970  2459  2412 10452   146    48   184     8\n",
            "    59   478   152   733   177   143     8    58  4060  8069 13355   138\n",
            "  8557    15   214   143   608   140   526  2121   171   247   177   137\n",
            "  4726  7336   139   395  4985   140   137   711   139  3959   597   144\n",
            "   137  1844   149    55  1175   288    15   140   203   137  1009   686\n",
            "   608  1701    13   143   197  3979   177  2514   137  1442   144    40\n",
            "   209   776    13   148    40    10   168 14198 13928   146  1260   470\n",
            "  1300   140   604  2118  2836  1873  9991   217  1006  2318   138    41\n",
            "    10   168  8469   146   422   400   480   138  1213   137  2541   139\n",
            "   143     8    58  1487   227  4319 10720   229   140   137  6310  8532\n",
            "   862    41  2215  6547 10768   139   137    61    15    40    15   145\n",
            "   141    40  7738  4120    13   152   569   260  3297   149   203    13\n",
            "   360   172    40   150   144   138   139   561    15    48   569   146\n",
            "     3   137   466  6192     3   138     3   665   139   193   707     3\n",
            "   204   207   185  1447   138   417   137   643  2731   182  8421   139\n",
            "   199   342   385   206   161  3920   253   137   566   151   137   153\n",
            "  1340  8845    15    45    14     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0], shape=(512,), dtype=int32)\n",
            "Recovered text after detokenizing:  tf.Tensor(b'this picture seemed way to slanted , it \\' s almost as bad as the drum beating of the right wing kooks who say everything is rosy in iraq . it paints a picture so unredeemable that i can \\' t help but wonder about it \\' s legitimacy and bias . also it seemed to meander from being about the murderous carnage of our troops to the lack of health care in the states for ptsd . to me the subject matter seemed confused , it only cared about portraying the military in a bad light , as a ) an organzation that uses mind control to turn ordinary peace loving civilians into baby killers and b ) an organization that once having used and spent the bodies of it \\' s soldiers then discards them to the despotic bureacracy of the v . a . this is a legitimate argument , but felt off topic for me , almost like a movie in and of itself . i felt that \" the war tapes \" and \" blood of my brother \" were much more fair and let the viewer draw some conclusions of their own rather than be beaten over the head with the film makers viewpoint . f - [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "input_sentence_ex = train_ds.take(1).get_single_element()[0][0]\n",
        "input_tokens_ex = tokenizer(input_sentence_ex)\n",
        "\n",
        "print(\"Sentence: \", input_sentence_ex)\n",
        "print(\"Tokens: \", input_tokens_ex)\n",
        "print(\"Recovered text after detokenizing: \", tokenizer.detokenize(input_tokens_ex))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e068a4e",
        "papermill": {
          "duration": 0.012432,
          "end_time": "2023-06-17T03:51:11.466168",
          "exception": false,
          "start_time": "2023-06-17T03:51:11.453736",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Formatting the dataset\n",
        "\n",
        "Next, we'll format our datasets in the form that will be fed to the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-17T03:51:11.493783Z",
          "iopub.status.busy": "2023-06-17T03:51:11.492858Z",
          "iopub.status.idle": "2023-06-17T03:51:13.173137Z",
          "shell.execute_reply": "2023-06-17T03:51:13.172182Z"
        },
        "id": "c0b47d88",
        "papermill": {
          "duration": 1.696545,
          "end_time": "2023-06-17T03:51:13.175659",
          "exception": false,
          "start_time": "2023-06-17T03:51:11.479114",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def format_dataset(sentence, label):\n",
        "    sentence = tokenizer(sentence)\n",
        "    return ({\"input_\": sentence}, label)\n",
        "\n",
        "def make_dataset(dataset):\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.shuffle(512).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_ds)\n",
        "val_ds = make_dataset(val_ds)\n",
        "test_ds = make_dataset(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting `test_ds` into `x_test` and `y_test` for evaluation purposes later"
      ],
      "metadata": {
        "id": "HByN_vwOdHGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test_ds.map(lambda x, y: x)\n",
        "print(x_test.cardinality())\n",
        "y_test = test_ds.map(lambda x, y: y)\n",
        "print(y_test.cardinality())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6mUaBw79vAT",
        "outputId": "741904e3-059e-44c3-f3a8-dcd38a6eef81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(391, shape=(), dtype=int64)\n",
            "tf.Tensor(391, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting into Numpy array for convenience\n",
        "\n",
        "y_test_np = []\n",
        "for batch in y_test.take(391):\n",
        "  for i in batch:\n",
        "    y_test_np.append(i.numpy())\n",
        "\n",
        "y_test=np.reshape(np.array(y_test_np), (-1,1))"
      ],
      "metadata": {
        "id": "JTZQjG-g-3Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe05f19e",
        "papermill": {
          "duration": 0.065117,
          "end_time": "2023-06-17T03:53:25.512882",
          "exception": false,
          "start_time": "2023-06-17T03:53:25.447765",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Constructing the Transformer model\n",
        "\n",
        "Model description: `Input` -> `TokenAndPositionEmbedding` -> `3 layer Transformer encoder stack` -> `GlobalAvgPooling1D` -> `20% Dropout` -> `30 unit ReLU activated Dense layer` -> `20 unit ReLU activated Dense layer` -> `2 unit Softmax activated Output`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-17T03:53:25.645935Z",
          "iopub.status.busy": "2023-06-17T03:53:25.645052Z",
          "iopub.status.idle": "2023-06-17T03:55:39.379097Z",
          "shell.execute_reply": "2023-06-17T03:55:39.378113Z"
        },
        "id": "ebc081a3",
        "papermill": {
          "duration": 133.802667,
          "end_time": "2023-06-17T03:55:39.381134",
          "exception": false,
          "start_time": "2023-06-17T03:53:25.578467",
          "status": "completed"
        },
        "tags": [],
        "outputId": "3260bfae-4421-46a9-aeee-76bcf93547cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ids (InputLayer)      [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddi  (None, None, 128)         1985536   \n",
            " ng (TokenAndPositionEmbedd                                      \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_encoder (Trans  (None, None, 128)         198272    \n",
            " formerEncoder)                                                  \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tra  (None, None, 128)         198272    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_2 (Tra  (None, None, 128)         198272    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 128)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2580481 (9.84 MB)\n",
            "Trainable params: 2580481 (9.84 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "313/313 [==============================] - 81s 203ms/step - loss: 0.4430 - accuracy: 0.7798 - val_loss: 0.2866 - val_accuracy: 0.8816\n",
            "Epoch 2/3\n",
            "313/313 [==============================] - 49s 157ms/step - loss: 0.2112 - accuracy: 0.9194 - val_loss: 0.2965 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "313/313 [==============================] - 49s 156ms/step - loss: 0.1507 - accuracy: 0.9445 - val_loss: 0.4046 - val_accuracy: 0.8688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c562b4f75e0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "input_ = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_\")\n",
        "\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "transformer_classifier = keras.Model(input_ids, outputs, name=\"transformer_classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "FivURoZ1cPI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5x7NYg0mBgK",
        "outputId": "b90e849d-8d23-428b-9a70-cbfd8c3770da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ (InputLayer)         [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddi  (None, None, 256)         5158400   \n",
            " ng (TokenAndPositionEmbedd                                      \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_encoder (Trans  (None, None, 256)         527104    \n",
            " formerEncoder)                                                  \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tra  (None, None, 256)         527104    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_2 (Tra  (None, None, 256)         527104    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 256)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 30)                7710      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                620       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6748063 (25.74 MB)\n",
            "Trainable params: 6748063 (25.74 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model\n",
        "\n",
        "Now that both the data and model are ready, we can fit the model to the data"
      ],
      "metadata": {
        "id": "41EUh0wCRwKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model, specifying number of epochs\n",
        "transformer_classifier.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "NFmc9B2GcFtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "The model's performance on the test set"
      ],
      "metadata": {
        "id": "VIiL9d8MRyEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the model's loss value and accuracy on the test set"
      ],
      "metadata": {
        "id": "T0lY1VJry-ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = transformer_classifier.evaluate(test_ds, batch_size=BATCH_SIZE)\n",
        "print(\"Test-loss: %f, Test-accuracy: %f\" % (test_loss, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX9eahLQFHlN",
        "outputId": "2682108a-9b73-4e98-c321-859569d680e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 28s 62ms/step - loss: 0.4890 - accuracy: 0.8432\n",
            "Test-loss: 0.489041, Test-accuracy: 0.843200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_probs = transformer_classifier.predict(x_test)\n",
        "y_predict = np.array((np.rint(y_probs)).astype(int))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bAqFjr_Faae",
        "outputId": "3dc31eb4-e0bb-4beb-d92f-bc65c53dc185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 24s 59ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us take a peek into the predictions and see how they compare with the ground truth"
      ],
      "metadata": {
        "id": "FYlJBkJFzE_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(15):\n",
        "  print(f\"True: {y_test[i]}, Predicted: {y_predict[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tLtcrLo9At2",
        "outputId": "c6c2d708-f281-4834-c7fd-088eb8e0fa57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True: [0], Predicted: [0]\n",
            "True: [0], Predicted: [0]\n",
            "True: [0], Predicted: [1]\n",
            "True: [1], Predicted: [1]\n",
            "True: [1], Predicted: [1]\n",
            "True: [0], Predicted: [0]\n",
            "True: [0], Predicted: [0]\n",
            "True: [0], Predicted: [0]\n",
            "True: [0], Predicted: [1]\n",
            "True: [0], Predicted: [1]\n",
            "True: [0], Predicted: [0]\n",
            "True: [1], Predicted: [0]\n",
            "True: [1], Predicted: [1]\n",
            "True: [1], Predicted: [1]\n",
            "True: [1], Predicted: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us view the Classification report and Confusion matrix of the model's predictions"
      ],
      "metadata": {
        "id": "nUBH-Ik5zHuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "% (transformer_classifier, metrics.classification_report(y_true = y_test, y_pred = y_predict)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "confMatrix = confusion_matrix(y_true = y_test, y_pred = y_predict)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix = confMatrix)\n",
        "\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "sVe0wsKOHGPg",
        "outputId": "fe05b84a-3932-454a-ed25-298f87ab4ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for classifier <keras.src.engine.functional.Functional object at 0x7c562b4f6950>:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85     12500\n",
            "           1       0.90      0.78      0.83     12500\n",
            "\n",
            "    accuracy                           0.84     25000\n",
            "   macro avg       0.85      0.84      0.84     25000\n",
            "weighted avg       0.85      0.84      0.84     25000\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Transformer model gives a `weighted-avg f1-score` of 0.84!"
      ],
      "metadata": {
        "id": "WoUtZvAC281z"
      }
    }
  ]
}